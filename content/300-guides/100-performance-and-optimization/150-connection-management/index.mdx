---
title: Connection management
metaTitle: ''
tocDepth: 2
---

<TopBlock>

Databases can open connections they can handle.

Although increasing the connection limit allows more processes to connect, there are significant performance cost on the database side. Moreover, many databases recommended not overpassing a certain connection number.

Prisma Client connection pool - connect show many connections query engine sends through, configurable connection limit. This guide

</TopBlock>

## Long-running processes

### Recommended connection limit

The recommended connection limit for long-running processes is the **default connection limit** (`num_physical_cpus * 2 + 1`) Ã· **number of application instances**.
 
For example, if your calculated connection limit is _10_ and you have _2_ instances of your app, the connection limit should be **no more than _5_**.

Optimizing your connection pool set the `connection_limit` manually.

### <inlinecode>PrismaClient</inlinecode> in long-running applications

In **long-running** applications, we recommend that you:

* âœ” Create **one** instance of `PrismaClient` and re-use it across your application
* âœ” Assign `PrismaClient` to a global variable _in dev environments only_ to [prevent hot reloading from creating new instances](#prevent-hot-reloading-from-creating-new-instances-of-prismaclient)

> **Note**: You [do not need to explicitly `$disconnect()`](connection-management#calling-disconnect-explicitly) in the context of a long-running application, such as a GraphQL server.

To re-use a single instance, create a module that exports a `PrismaClient` object:

```ts file=client.ts
import { PrismaClient } from "@prisma/client"

let prisma = new PrismaClient() 

export default prisma
```

The object is [cached](https://nodejs.org/api/modules.html#modules_caching) the first time the module is imported. Subsequent requests return the cached object rather than creating a new `PrismaClient`:

```ts file=app.ts
import prisma from './client'

async function main() {
  const allUsers = await prisma.user.findMany();
}

main();
```

#### Prevent hot reloading from creating new instances of `PrismaClient`

Frameworks like [Next.js](https://nextjs.org/) support hot reloading of changed files, which enables you to see changes to your application without restarting. However, if the framework refreshes the module responsible for exporting `PrismaClient`, this can result in **additional, unwanted instances of `PrismaClient` in a development environment**.

As a workaround, you can store `PrismaClient` as a global variable in development environments only, as global variables are not reloaded:

```ts file=client.ts
import { PrismaClient } from "@prisma/client"

declare global {
    namespace NodeJS {
        interface Global {
            prisma: PrismaClient;
        }
    }
}

let prisma: PrismaClient;

if (process.env.NODE_ENV === "production") {
  prisma = new PrismaClient()
} else {
  if (!global.prisma) {
    global.prisma = new PrismaClient()
  }

  prisma = global.prisma
}

export default prisma
```

The way that you import and use the client does not change:

```ts file=app.ts
import prisma from './client'

async function main() {
    const allUsers = await prisma.user.findMany();
}

main();
```

## Serverless environments (FaaS)

### The serverless challenge

In a serverless environment, each function creates **its own instance** of `PrismaClient`, and each client instance has its own connection pool. 

Consider the following example, where a single AWS Lambda function uses `PrismClient` to connect to a database. The `connection_limit` is **3**:

![An AWS Lambda function connecting to a database.](./serverless-connections.png)

A traffic spike causes AWS Lambda to spawn two additional lambdas to handle the increased load. Each lambda creates an instance of `PrismaClient`, each with a `connection_limit` of **3**, which results in a maximum of **9** connections to the database:

![Three AWS Lambda function connecting to a database.](./serverless-connections-2.png)
 
200 _concurrent functions_ (and therefore 600 possible connections) responding to a traffic spike ðŸ“ˆ can exhaust the database connection limit very quickly.

* [Set `connection_limit` is set to `1`](#recommended-connection-limit-1)
* Use an external connection pooler like PgBouncer


### Recommended connection limit

#### Without an external connection pooler

#### With an external connection pooler

We recommend that you set the `connection_limit` to **1** if you are **not** using an external connection pooler. because each incoming request starts a short-lived Node.js process. This can cause the database connection pool to be quickly exhausted from a short spike in user traffic.



<TabbedContent tabs={[<FileWithIcon text="PostgreSQL" icon="database"/>, <FileWithIcon text="MySQL" icon="database"/>]}>
<tab>

  ```
  postgresql://USER:PASSWORD@HOST:PORT/DATABASE?connection_limit=1
  ```

</tab>
<tab>

  ```
  mysql://USER:PASSWORD@HOST:PORT/DATABASE?connection_limit=1
  ```

</tab>
</TabbedContent>


### <inlinecode>PrismaClient</inlinecode> in serverless environments


#### Instantiate `PrismaClient` outside the handler

Creating `PrismaClient` [outside of function handler](https://github.com/prisma/e2e-tests/blob/5d1041d3f19245d3d237d959eca94d1d796e3a52/platforms/serverless-lambda/index.ts#L3) to increase the chances of reuse

Instantiates `PrismaClient` outside scope of handler (default pool size is X) - as long as the handler remains 'warm' (in use), the connection is reusable:

```ts highlight=3;normal
import { PrismaClient, Prisma } from '@prisma/client'

const client = new PrismaClient()

export async function handler() {
    /* ... */
}
```
#### Do not explicitly <inlinecode>$disconnect()</inlinecode>

### Container reuse

It is not guaranteed that subsequent nearby invocations of a function will hit the same container. AWS can choose to create a new container at any time. 

Code should assume the container to be stateless and create a connection only if it does not exist. Prisma Client JS already implements that logic.

### Zombie connections

Containers that are marked to be removed and are not being reused still keep a connection open and can stay in that state for some time (unknown and not documented from AWS), this can lead to sub-optimal utilization of the DB connections

One potential solution is to use a lower idle connection timeout. Another solution can be to clean up the idle connections in a separate service<sup>1, 2</sup>.         |

<br />
<sup>
  1. Note that these are recommendations and not best practices. These would vary from system to
  system.
</sup>
<br />
<sup>
  2.{' '}
  <a href="https://github.com/jeremydaly/serverless-mysql">
    <inlineCode>serverless-mysql</inlineCode>
  </a>{' '}
  is a library that implements this idea.
</sup>

### Concurrency limits

Depending on your serverless concurrency limit (the number of serverless functions running), you might still exhaust your database's connection limit. This can happen when too many functions are invoked concurrently (i.e. the number of concurrent Lambdas that each hold a DB connection exceeds the connection limit of your database). To prevent this, [set your serverless concurrency limit](https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html) to a number lower than the connection limit of your database (as you might want to be able to connect from another client for other purposes).

## Optimizing the connection pool

If you experience **connection pool timeouts**

A connection pool timeout can occur if many users are accessing your app simultanously or if you send a large number of queries in parallel (for example, using `await Promise.all()`). You can use the `connection_limit` and `pool_timeout` connection string parameters to tune the connection pool.

### Increasing the connection limit

Increasing the connection limit allows the query engine to process a larger number of queries in parallel. Be aware that your database must be able to support the increased number of concurrent connections, otherwise you will **exhaust the connection limit**.

To increase the connection limit, manually set the `connection_limit` to a higher number:

```prisma
datasource db {
  provider = "postgresql"
  url      = "postgresql://johndoe:mypassword@localhost:5432/mydb?connection_limit=40"
}
```

### Disabling the pool timeout

Disabling the pool timeout prevents the query engine from throwing an exception and allows the queue to build up. You might consider this approach in the following scenario:

* You are submitting a large number of queries for a limited time - for example, as part of a job to import or update every customer in your database.
* You have already increased the `connection_limit`.
* You are confident that the queue will not grow beyond a certain size, otherwise **you will eventually run out of RAM**.

To disable the pool timeout, set the `pool_timeout` parameter to `0`:

```prisma
datasource db {
  provider = "postgresql"
  url      = "postgresql://johndoe:mypassword@localhost:5432/mydb?connection_limit=5&pool_timeout=0"
}
```

## External connection poolers

### PgBouncer

PostgreSQL supports only a certain amount of concurrent connections, and this limit can be reached quite fast when the service usage goes up â€“ especially in serverless environments.

A connection pooler like PgBouncer prevents your application from exhausting the database's connection limit.

PgBouncer holds a connection pool to the database and proxies incoming client connections by sitting between Prisma Client and the database. This reduces the number of processes a database has to handle at any given time. PgBouncer passes on a limited number of connections to the database and queues additional connections for delivery when space becomes available.

